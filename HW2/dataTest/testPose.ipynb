{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualization utilies.\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "\n",
    "def show_points(points, title):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim3d([-2, 2])\n",
    "    ax.set_ylim3d([-2, 2])\n",
    "    ax.set_zlim3d([0, 4])\n",
    "    ax.scatter(points[:, 0], points[:, 2], points[:, 1])\n",
    "\n",
    "def compare_points(points1, points2):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.set_xlim3d([-2, 2])\n",
    "    ax.set_ylim3d([-2, 2])\n",
    "    ax.set_zlim3d([0, 4])\n",
    "    ax.scatter(points1[:, 0], points1[:, 2], points1[:, 1])\n",
    "    ax.scatter(points2[:, 0], points2[:, 2], points2[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.07499998 -0.02499997  0.01499998]\n",
      " [ 0.07499998 -0.02499997  0.01499998]\n",
      " [ 0.07499998  0.02499997  0.01499998]\n",
      " [-0.07499998 -0.02499997  0.01499998]\n",
      " [ 0.07499998  0.02499997  0.01499998]\n",
      " [-0.07499998  0.02499997  0.01499998]\n",
      " [ 0.07499998  0.02499997 -0.01499998]\n",
      " [ 0.07499998 -0.02499997 -0.01499998]\n",
      " [-0.07499998 -0.02499997 -0.01499998]\n",
      " [-0.07499998  0.02499997 -0.01499998]\n",
      " [ 0.07499998  0.02499997 -0.01499998]\n",
      " [-0.07499998 -0.02499997 -0.01499998]\n",
      " [-0.07499998  0.02499997  0.01499998]\n",
      " [-0.07499998  0.02499997 -0.01499998]\n",
      " [-0.07499998 -0.02499997 -0.01499998]\n",
      " [-0.07499998 -0.02499997  0.01499998]\n",
      " [-0.07499998  0.02499997  0.01499998]\n",
      " [-0.07499998 -0.02499997 -0.01499998]\n",
      " [ 0.07499998 -0.02499997 -0.01499998]\n",
      " [ 0.07499998  0.02499997 -0.01499998]\n",
      " [ 0.07499998  0.02499997  0.01499998]\n",
      " [ 0.07499998 -0.02499997 -0.01499998]\n",
      " [ 0.07499998  0.02499997  0.01499998]\n",
      " [ 0.07499998 -0.02499997  0.01499998]\n",
      " [ 0.07499998 -0.02499997  0.01499998]\n",
      " [-0.07499998 -0.02499997  0.01499998]\n",
      " [-0.07499998 -0.02499997 -0.01499998]\n",
      " [ 0.07499998 -0.02499997 -0.01499998]\n",
      " [ 0.07499998 -0.02499997  0.01499998]\n",
      " [-0.07499998 -0.02499997 -0.01499998]\n",
      " [-0.07499998  0.02499997 -0.01499998]\n",
      " [-0.07499998  0.02499997  0.01499998]\n",
      " [ 0.07499998  0.02499997  0.01499998]\n",
      " [-0.07499998  0.02499997 -0.01499998]\n",
      " [ 0.07499998  0.02499997  0.01499998]\n",
      " [ 0.07499998  0.02499997 -0.01499998]]\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# Load the canonical-space object point clouds\n",
    "import trimesh\n",
    "import collada\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def fps_downsample(points, number_of_points_to_sample):\n",
    "  selected_points = np.zeros((number_of_points_to_sample, 3))\n",
    "  dist = np.ones(points.shape[0]) * np.inf # distance to the selected set\n",
    "  for i in tqdm(range(number_of_points_to_sample)):\n",
    "      # pick the point with max dist\n",
    "      idx = np.argmax(dist)\n",
    "      selected_points[i] = points[idx]\n",
    "      dist_ = ((points - selected_points[i]) ** 2).sum(-1)\n",
    "      dist = np.minimum(dist, dist_)\n",
    "  return selected_points\n",
    "\n",
    "object_models_file = \"models/objects_v1.csv\"\n",
    "object_models_info = pd.read_csv(object_models_file)\n",
    "object_models_name = object_models_info[\"object\"].to_list()\n",
    "object_models_location = object_models_info[\"location\"].to_list()\n",
    "object_models_num = len(object_models_name)\n",
    "\n",
    "\n",
    "object_models = {}\n",
    "for object_name, object_mesh_dir in zip(object_models_name, object_models_location):\n",
    "  object_mesh_path = os.path.join(object_mesh_dir, \"visual_meshes\", \"visual.dae\")\n",
    "  # Collada-based loading\n",
    "  object_mesh = trimesh.exchange.dae.load_collada(object_mesh_path)\n",
    "  mesh_name = object_mesh['graph'][0]['geometry']\n",
    "  object_models[object_name] = object_mesh['geometry'][mesh_name]['vertices']\n",
    "  # Trimesh-based loading\n",
    "  # object_mesh = trimesh.load(object_mesh_path, force='mesh')\n",
    "  # object_models[object_name] = object_mesh.vertices\n",
    "  # print(object_mesh)\n",
    "\n",
    "# object_models with key=objectName, value=objectPointCloud\n",
    "# print(object_models_info)\n",
    "print(object_models[\"jenga\"])\n",
    "print(len(object_models[\"jenga\"]))\n",
    "# print(np.unique(object_models[\"jenga\"]))\n",
    "# print(len(object_models))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Data loading helpers\"\"\"\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import utils\n",
    "import open3d as o3d\n",
    "# # Helper function for the reconstruction of the target point cloud\n",
    "# rgb = np.array(Image.open(rgb_files[0])) / 255   # convert 0-255 to 0-1\n",
    "# depth = np.array(Image.open(depth_files[0])) / 1000   # convert from mm to m\n",
    "# label = np.array(Image.open(label_files[0]))\n",
    "# meta = load_pickle(meta_files[0])\n",
    "# intrinsic = meta['intrinsic']\n",
    "# z = depth\n",
    "# v, u = np.indices(z.shape)\n",
    "# uv1 = np.stack([u + 0.5, v + 0.5, np.ones_like(z)], axis=-1)\n",
    "# points_viewer = uv1 @ np.linalg.inv(intrinsic).T * z[..., None]  # [H, W, 3]\n",
    "# # print(points_viewer.shape)\n",
    "# # print(points_viewer.shape[0]*points_viewer.shape[1])\n",
    "# # print(points_viewer)\n",
    "\n",
    "def load_pickle(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def dump_json(sample, path):\n",
    "  with open(path, 'w') as fp:\n",
    "    json.dump(sample, fp)\n",
    "  return 0\n",
    "\n",
    "def load_json(path):\n",
    "  f = open(path)\n",
    "  data = json.load(f)\n",
    "  return data\n",
    "\n",
    "def get_point_cloud(depth, intrinsic):\n",
    "  z = depth\n",
    "  v, u = np.indices(z.shape)\n",
    "  uv1 = np.stack([u + 0.5, v + 0.5, np.ones_like(z)], axis=-1)\n",
    "  points_viewer = uv1 @ np.linalg.inv(intrinsic).T * z[..., None]  # [H, W, 3]\n",
    "  return points_viewer\n",
    "\n",
    "def pts_to_o3d_pcd(pts):\n",
    "  \"\"\"Transform to o3d pcd\"\"\"\n",
    "  pcd = o3d.geometry.PointCloud()\n",
    "  pcd.points = o3d.utility.Vector3dVector(pts)\n",
    "  return pcd\n",
    "\n",
    "def o3dvis(pts):\n",
    "    o3d.visualization.draw_geometries([pts_to_o3d_pcd(pt) for pt in pts])\n",
    "    return 0\n",
    "\n",
    "def get_object_point_cloud(test_image_label, object_id, test_depth, intrinsic):\n",
    "  # print(np.where(test_image_label==object_id))\n",
    "  # print(test_image_label[327][654])\n",
    "  test_image_label[np.where(test_image_label==object_id)] = 255\n",
    "  # print(test_image_label[327][654])\n",
    "  # print(np.where(test_image_label==255))\n",
    "  test_image_label[np.where(test_image_label!=255)] = 0\n",
    "  test_image_label[np.where(test_image_label==255)] = 1\n",
    "  test_object_depth = test_depth * test_image_label\n",
    "  test_pcd_target = get_point_cloud(test_object_depth, intrinsic)\n",
    "  # (H, W, dim) = test_pcd_target.shape\n",
    "  # filter out target object point cloud\n",
    "  # print(test_pcd_target.shape)\n",
    "  # print(test_pcd_target)\n",
    "  # print((test_pcd_target[:,0]!=0)|(test_pcd_target[:,1]!=0)|(test_pcd_target[:,2]!=0))\n",
    "  test_pcd_target = test_pcd_target.reshape(-1, test_pcd_target.shape[-1]) # reshape to (H*W, 3)\n",
    "  test_pcd_target = test_pcd_target[(test_pcd_target[:,0]!=0)|(test_pcd_target[:,1]!=0)|(test_pcd_target[:,2]!=0)]\n",
    "  return test_pcd_target\n",
    "\n",
    "\n",
    "def get_meta(meta_path):\n",
    "  return load_pickle(meta_path)\n",
    "\n",
    "def get_depth(depth_path):\n",
    "  return (np.array(Image.open(depth_path))/1000)\n",
    "\n",
    "def get_label(label_path):\n",
    "  return np.array(Image.open(label_path))\n",
    "\n",
    "\n",
    "def dump_json(sample, path):\n",
    "  with open(path, 'w') as fp:\n",
    "    json.dump(sample, fp)\n",
    "  return 0\n",
    "\n",
    "def load_json(path):\n",
    "  f = open(path)\n",
    "  data = json.load(f)\n",
    "  return data\n",
    "\n",
    "def get_point_cloud(depth, intrinsic):\n",
    "  z = depth\n",
    "  v, u = np.indices(z.shape)\n",
    "  uv1 = np.stack([u + 0.5, v + 0.5, np.ones_like(z)], axis=-1)\n",
    "  points_viewer = uv1 @ np.linalg.inv(intrinsic).T * z[..., None]  # [H, W, 3]\n",
    "  return points_viewer\n",
    "\n",
    "\n",
    "def get_meta(meta_path):\n",
    "  return load_pickle(meta_path)\n",
    "\n",
    "def get_depth(depth_path):\n",
    "  return (np.array(Image.open(depth_path))/1000)\n",
    "\n",
    "def get_label(label_path):\n",
    "  return np.array(Image.open(label_path))\n",
    "\n",
    "\n",
    "\"\"\"Metric and visualization.\"\"\"\n",
    "\n",
    "def compute_rre(R_est: np.ndarray, R_gt: np.ndarray):\n",
    "    \"\"\"Compute the relative rotation error (geodesic distance of rotation).\"\"\"\n",
    "    assert R_est.shape == (3, 3), 'R_est: expected shape (3, 3), received shape {}.'.format(R_est.shape)\n",
    "    assert R_gt.shape == (3, 3), 'R_gt: expected shape (3, 3), received shape {}.'.format(R_gt.shape)\n",
    "    # relative rotation error (RRE)\n",
    "    # Rotational degree loss (not objective of optimization)\n",
    "    rre = np.arccos(np.clip(0.5 * (np.trace(R_est.T @ R_gt) - 1), -1.0, 1.0))\n",
    "    return rre\n",
    "\n",
    "\n",
    "def compute_rte(t_est: np.ndarray, t_gt: np.ndarray):\n",
    "    assert t_est.shape == (3,), 't_est: expected shape (3,), received shape {}.'.format(t_est.shape)\n",
    "    assert t_gt.shape == (3,), 't_gt: expected shape (3,), received shape {}.'.format(t_gt.shape)\n",
    "    # relative translation error (RTE)\n",
    "    rte = np.linalg.norm(t_est - t_gt) # Resembling MSE loss\n",
    "    return rte\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['poses_world', 'extents', 'scales', 'object_ids', 'object_names', 'extrinsic', 'intrinsic'])\n",
      "master_chef_can\n",
      "src and tg len:\n",
      "4417 36\n",
      ":: Load two point clouds and disturb initial pose.\n",
      ":: Downsample with a voxel size 0.050.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      ":: Estimate normal with search radius 0.100.\n",
      ":: Compute FPFH feature with search radius 0.250.\n",
      "PointCloud with 36 points. PointCloud with 4417 points.\n",
      "PointCloud with 36 points. PointCloud with 46 points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:01<00:00, 185.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cdist list:\n",
      "[1.892937505737352, 1.8929375057373514, 1.8464653502871498, 1.8929375057373459, 1.876322193424986, 1.8929375057373463, 1.7850174779920416, 1.8464653502871424, 1.876322193424991, 1.8464653502871444, 1.7850174779920396, 1.8464653502871469, 1.8464653502871449, 1.8929375057373496, 1.8929375057373503, 1.8464653502871466, 1.8763221934249876, 1.8929375057373499, 1.8464653502871475, 1.8464653502871429, 1.846465350287149, 1.8929375057373479, 1.7996464711912648, 1.7850174779920422, 1.846465350287146, 1.846465350287145, 1.8464653502871484, 1.8929375057373494, 1.846465350287144, 1.8763221934249859, 1.8763221934249867, 1.8929375057373459, 1.892937505737348, 1.8464653502871444, 1.846465350287145, 1.846465350287143, 1.7996464711912676, 1.7996464711912676, 1.892937505737349, 1.8763221934249876, 1.8464653502871433, 1.8464653502871458, 1.8763221934249883, 1.846465350287149, 1.8763221934249859, 1.7996464711912672, 1.7850174779920427, 1.7850174779920447, 1.7850174779920431, 1.8464653502871478, 1.8464653502871458, 1.8464653502871442, 1.8464653502871469, 1.8464653502871462, 1.8464653502871415, 1.8464653502871473, 1.846465350287142, 1.8464653502871495, 1.876322193424984, 1.8763221934249827, 1.7850174779920451, 1.7850174779920425, 1.8763221934249863, 1.8763221934249845, 1.8464653502871458, 1.8929375057373494, 1.846465350287146, 1.8464653502871442, 1.8763221934249892, 1.8763221934249887, 1.8464653502871455, 1.8763221934249854, 1.8763221934249847, 1.892937505737344, 1.8464653502871493, 1.7850174779920445, 1.7850174779920414, 1.8763221934249892, 1.846465350287145, 1.78501747799204, 1.8929375057373508, 1.8763221934249856, 1.8464653502871444, 1.8464653502871473, 1.8464653502871489, 1.8464653502871473, 1.8464653502871489, 1.8763221934249887, 1.846465350287146, 1.8464653502871449, 1.8464653502871478, 1.8464653502871475, 1.8464653502871486, 1.8464653502871473, 1.8464653502871413, 1.8464653502871484, 1.846465350287141, 1.8929375057373499, 1.8763221934249827, 1.846465350287147, 1.7850174779920436, 1.8763221934249847, 1.785017477992042, 1.8464653502871478, 1.8464653502871475, 1.8763221934249916, 1.8464653502871489, 1.8464653502871475, 1.8763221934249859, 1.846465350287146, 1.8929375057373496, 1.892937505737348, 1.892937505737348, 1.89293750573735, 1.8763221934249845, 1.8464653502871424, 1.785017477992042, 1.846465350287145, 1.8763221934249872, 1.8464653502871449, 1.8929375057373523, 1.8464653502871442, 1.8464653502871444, 1.846465350287148, 1.8464653502871458, 1.8464653502871466, 1.785017477992042, 1.846465350287147, 1.8929375057373476, 1.8464653502871422, 1.785017477992045, 1.8464653502871415, 1.8464653502871486, 1.8464653502871484, 1.785017477992044, 1.84646535028715, 1.785017477992043, 1.8763221934249872, 1.8464653502871453, 1.8464653502871455, 1.8763221934249847, 1.8464653502871455, 1.785017477992043, 1.7996464711912687, 1.8464653502871444, 1.8464653502871449, 1.846465350287145, 1.8464653502871426, 1.8763221934249852, 1.7850174779920427, 1.8929375057373488, 1.8929375057373499, 1.8464653502871469, 1.8464653502871446, 1.8763221934249876, 1.8464653502871435, 1.8763221934249847, 1.8464653502871435, 1.846465350287147, 1.8763221934249867, 1.8464653502871446, 1.8929375057373508, 1.8464653502871478, 1.8464653502871478, 1.846465350287148, 1.8464653502871464, 1.876322193424987, 1.8464653502871489, 1.8464653502871446, 1.8763221934249872, 1.8763221934249876, 1.7850174779920416, 1.8763221934249865, 1.846465350287148, 1.846465350287148, 1.8464653502871475, 1.876322193424988, 1.8464653502871475, 1.7850174779920431, 1.7850174779920442, 1.8464653502871458, 1.8464653502871466, 1.7850174779920414, 1.8464653502871469, 1.7850174779920438, 1.7850174779920438, 1.8464653502871464, 1.8763221934249896, 1.8763221934249938, 1.8464653502871449, 1.7850174779920431, 1.8763221934249816, 1.8763221934249863, 1.7996464711912696, 1.7850174779920434, 1.8464653502871484, 1.785017477992043, 1.785017477992045, 1.8464653502871464, 1.8929375057373485, 1.8464653502871424, 1.8464653502871455, 1.8464653502871449, 1.8464653502871455, 1.785017477992044, 1.8464653502871469, 1.8464653502871462, 1.8464653502871455, 1.846465350287145, 1.8464653502871453, 1.876322193424986, 1.7850174779920418, 1.846465350287148, 1.892937505737351, 1.7850174779920418, 1.8464653502871442, 1.7850174779920411, 1.8464653502871409, 1.8464653502871462, 1.785017477992041, 1.8464653502871415, 1.8763221934249836, 1.8929375057373474, 1.8929375057373519, 1.8464653502871486, 1.846465350287148, 1.8464653502871455, 1.846465350287148, 1.892937505737348, 1.8464653502871458, 1.7850174779920434, 1.876322193424986, 1.7850174779920405, 1.8464653502871489, 1.8464653502871466, 1.8464653502871486, 1.8464653502871478, 1.8464653502871433, 1.8464653502871473, 1.846465350287145, 1.876322193424991, 1.876322193424985, 1.846465350287147, 1.8464653502871418, 1.7850174779920431, 1.84646535028715, 1.7850174779920416, 1.8763221934249845, 1.8929375057373479, 1.8763221934249867, 1.8464653502871462, 1.876322193424987, 1.8464653502871478, 1.846465350287148, 1.7996464711912656, 1.8763221934249878, 1.8929375057373474, 1.846465350287144, 1.846465350287146, 1.7850174779920431, 1.846465350287146, 1.785017477992043, 1.7850174779920418, 1.846465350287146, 1.892937505737348, 1.8464653502871489, 1.7996464711912679, 1.846465350287148, 1.8464653502871449, 1.8763221934249856, 1.8464653502871462, 1.8464653502871435, 1.785017477992043, 1.8464653502871442, 1.846465350287147, 1.8464653502871458, 1.8464653502871466, 1.8763221934249863, 1.8464653502871453, 1.8464653502871478, 1.7850174779920462, 1.8464653502871458, 1.8464653502871442, 1.7850174779920431, 1.8464653502871484, 1.8464653502871455, 1.8763221934249892, 1.846465350287144, 1.846465350287148, 1.8763221934249878, 1.8464653502871438, 1.8464653502871444, 1.8464653502871489, 1.8763221934249878, 1.846465350287149, 1.8929375057373516, 1.8464653502871455, 1.892937505737347, 1.8763221934249903, 1.8763221934249854]\n",
      "1.7850174779920396\n",
      "10\n",
      "The following gives rre and rte max indices and values:\n",
      "177.83601880692183 266\n",
      "0.0035854834415732133 202\n",
      "Good list under current parameter sets:\n",
      "[177.09336043 177.09336043 177.09336043 177.09336043 177.09336043\n",
      " 177.09336043 177.09336043 177.09336043 177.09336043 177.09336043\n",
      " 177.09336043 177.09336043 177.09336043 177.09336043 177.09336043\n",
      " 177.09336043 177.09336043 177.09336043 177.09336043 177.09336043\n",
      " 177.09336043 177.09336043 177.09336043 177.09336043 177.09336043\n",
      " 177.09336043 177.09336043 177.09336043 177.09336043 177.09336043\n",
      " 177.09336043 177.09336043 177.09336043 177.09336043 177.09336043\n",
      " 177.09336043 177.09336043 177.09336043 177.09336043 177.09336043\n",
      " 177.09336043 177.09336043 177.09336043 177.09336043 177.09336043] 45\n",
      "Good list rmse and cdist:\n",
      "[-1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289\n",
      " -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289\n",
      " -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289\n",
      " -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289\n",
      " -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289\n",
      " -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289\n",
      " -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289 -1.4898289\n",
      " -1.4898289 -1.4898289 -1.4898289]\n",
      "[-1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843\n",
      " -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843\n",
      " -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843\n",
      " -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843\n",
      " -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843\n",
      " -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843\n",
      " -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843 -1.91914843\n",
      " -1.91914843 -1.91914843 -1.91914843]\n",
      "Fractioned optimal rmse and cdist:\n",
      "-1.4898289035162313\n",
      "-1.9191484341614231\n",
      "Global optimal rmse and cdist, with indices:\n",
      "-1.4898289035162313 182\n",
      "-1.9191484341614782 10\n",
      "36 36\n",
      "(36, 3)\n",
      "(4417, 3)\n",
      "GT T:\n",
      "[[ 8.96165788e-01  4.43719357e-01 -2.05287742e-09  1.54664963e-01]\n",
      " [-4.43719357e-01  8.96165788e-01 -1.38711505e-08 -2.47322485e-01]\n",
      " [-4.31517888e-09  1.33417517e-08  1.00000000e+00  1.49999792e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "GT T world:\n",
      "[[ 8.96165788e-01  4.43719357e-01 -2.05287742e-09  1.54664963e-01]\n",
      " [-4.43719357e-01  8.96165788e-01 -1.38711505e-08 -2.47322485e-01]\n",
      " [-4.31517888e-09  1.33417517e-08  1.00000000e+00  1.49999792e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "pred T:\n",
      "[[ 0.63203194  0.50852351 -0.5847559  -0.26741232]\n",
      " [-0.63488095  0.77247504 -0.01443904  0.03340882]\n",
      " [ 0.44436675  0.38037632  0.81108079  0.74044444]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "pred T world:\n",
      "[[-0.84751983  0.29894545 -0.43856777  0.1590942 ]\n",
      " [ 0.53073941  0.48524081 -0.69487912 -0.24091195]\n",
      " [ 0.00508006 -0.82168906 -0.56991344  0.01639067]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "rre=177.09336042720813, rte=0.007914994587274155\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Visualization on comparing between train pose-transformed point clouds.\"\"\"\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4559,\n",
    "                                      front=[0.6452, -0.3036, -0.7011],\n",
    "                                      lookat=[1.9892, 2.0208, 1.8945],\n",
    "                                      up=[-0.2779, -0.9482, 0.1556])\n",
    "\n",
    "def get_o3d_icp_tensor(source_pcd, target_pcd):\n",
    "  # T = icp(source_pcd, target_pcd, 150)\n",
    "  source_pcd_o3d, target_pcd_o3d = o3d.t.geometry.PointCloud(), o3d.t.geometry.PointCloud()\n",
    "  # print(source_pcd)\n",
    "  source_pcd_o3d.point.positions = o3d.core.Tensor(source_pcd, dtype=o3d.core.Dtype.Float64)\n",
    "  # source_pcd_o3d.estimate_normals(o3d.geometry.KDTreeSearchParamKNN(knn=50))\n",
    "  target_pcd_o3d.point.positions = o3d.core.Tensor(target_pcd, dtype=o3d.core.Dtype.Float64)\n",
    "  # Search distance for Nearest Neighbour Search [Hybrid-Search is used].\n",
    "  max_correspondence_distance = 1\n",
    "  init = o3d.core.Tensor.eye(4, o3d.core.Dtype.Float64)\n",
    "  # Select the `Estimation Method`, and `Robust Kernel` (for outlier-rejection).\n",
    "  treg = o3d.cpu.pybind.t.pipelines.registration\n",
    "  estimation = treg.TransformationEstimationPointToPoint()\n",
    "  callback_after_iteration = lambda updated_result_dict : print(\"Iteration Index: {}, Fitness: {}, Inlier RMSE: {},\".format(\n",
    "    updated_result_dict[\"iteration_index\"].item(), \\\n",
    "    updated_result_dict[\"fitness\"].item(), \\\n",
    "    updated_result_dict[\"inlier_rmse\"].item())) \\\n",
    "\n",
    "  # Convergence-Criteria for Vanilla ICP\n",
    "  criteria = treg.ICPConvergenceCriteria(relative_fitness=0.0000000000001,\n",
    "                      relative_rmse=0.0000000000001,\n",
    "                      max_iteration=100)\n",
    "\n",
    "  # Down-sampling voxel-size.\n",
    "  # voxel_size = 0.0016625\n",
    "  # voxel_size = 0.003125\n",
    "  voxel_size = 0.00625\n",
    "  # voxel_size = 0.0125\n",
    "\n",
    "  # Save iteration wise `fitness`, `inlier_rmse`, etc. to analyse and tune result.\n",
    "  save_loss_log = True\n",
    "  s = time.time()\n",
    "\n",
    "  # voxel_size = 0.05  # means 5cm for this dataset\n",
    "  # source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(voxel_size, source_pcd_o3d, target_pcd_o3d)\n",
    "  # result_ransac = execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "  # init = o3d.core.Tensor(result_ransac.transformation, dtype=o3d.core.Dtype.Float64)\n",
    "\n",
    "  registration_icp = treg.icp(source_pcd_o3d, target_pcd_o3d, max_correspondence_distance, init, estimation, criteria, voxel_size, callback_after_iteration)\n",
    "  icp_time = time.time() - s\n",
    "  T = registration_icp.transformation\n",
    "  T = T.numpy()\n",
    "  return T\n",
    "\n",
    "def execute_fast_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "  distance_threshold = voxel_size * 0.5\n",
    "  print(\":: Apply fast global registration with distance threshold %.3f\" \\\n",
    "          % distance_threshold)\n",
    "  result = o3d.pipelines.registration.registration_fgr_based_on_feature_matching(\n",
    "      source_down, target_down, source_fpfh, target_fpfh,\n",
    "      o3d.pipelines.registration.FastGlobalRegistrationOption(\n",
    "          maximum_correspondence_distance=distance_threshold))\n",
    "  return result\n",
    "\n",
    "def refine_registration(source, target, source_fpfh, target_fpfh, voxel_size, init):\n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    print(\":: Point-to-plane ICP registration is applied on original point\")\n",
    "    print(\"   clouds to refine the alignment. This time we use a strict\")\n",
    "    print(\"   distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, init,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPlane())\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "icp_global_voxel_size = 0.05\n",
    "icp_dist_threshold = 5\n",
    "init_random_time = 300\n",
    "max_preproc_nn_normal = 50\n",
    "max_preproc_nn_fpfh = 100\n",
    "tgSrcFactor = 1.3\n",
    "dist_voxel_factor = 3\n",
    "fps_dnsamp_factor = 2000\n",
    "cdistFrac = 0.1\n",
    "heavy_dnsamp_frac = 9/14\n",
    "# heavy_dnsamp_frac = 5/7\n",
    "# heavy_dnsamp_frac = 4/7\n",
    "\n",
    "\n",
    "def get_o3d_icp(source_pcd, target_pcd, init=np.eye(4), icp_dist_threshold=icp_dist_threshold):\n",
    "  # T = icp(source_pcd, target_pcd, 150)\n",
    "  source_pcd_o3d, target_pcd_o3d = o3d.geometry.PointCloud(), o3d.geometry.PointCloud()\n",
    "  # print(source_pcd)\n",
    "  source_pcd_o3d.points = o3d.utility.Vector3dVector(source_pcd)\n",
    "  # source_pcd_o3d.estimate_normals(o3d.geometry.KDTreeSearchParamKNN(knn=50))\n",
    "  target_pcd_o3d.points = o3d.utility.Vector3dVector(target_pcd)\n",
    "  # target_pcd_o3d.estimate_normals(o3d.geometry.KDTreeSearchParamKNN(knn=50))\n",
    "  # print(source_pcd_o3d)\n",
    "  # print(target_pcd_o3d)\n",
    "  # init = np.random.rand(4,4)\n",
    "  # init = -1 + init * 2\n",
    "  # init[-1] = np.zeros(4)\n",
    "  # print(init)\n",
    "  # init[0,0] = 2\n",
    "  T = o3d.pipelines.registration.registration_icp( \\\n",
    "        source_pcd_o3d, target_pcd_o3d, icp_dist_threshold, init, \\\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(), \\\n",
    "        # o3d.pipelines.registration.TransformationEstimationPointToPlane(), \\\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(relative_fitness=0.00001, \\\n",
    "                                 relative_rmse=0.00001, \\\n",
    "                                 max_iteration=500))\n",
    "  # T = icp(source_pcd, target_pcd)\n",
    "  # print(T.inlier_rmse)\n",
    "  # print(T.fitness)\n",
    "  # print(T.correspondence_set)\n",
    "  return T\n",
    "\n",
    "# tgSrcFactorDict = {\n",
    "#    58: 1.2\n",
    "\n",
    "# }\n",
    "\n",
    "def half_voxel_dnsample(source, voxel_size, heavy_dnsamp_frac=heavy_dnsamp_frac):\n",
    "  pts = source.points\n",
    "  size = len(pts)\n",
    "  # print(pts.shape)\n",
    "  first_half = o3d_Vec_to_o3d_pcd(pts[:int(size*heavy_dnsamp_frac)])\n",
    "  first_half = first_half.voxel_down_sample(voxel_size=voxel_size) # heavily down-sampled side\n",
    "  secn_half = o3d_Vec_to_o3d_pcd(pts[int(size*heavy_dnsamp_frac):])\n",
    "  secn_half = secn_half.voxel_down_sample(voxel_size=voxel_size*0.1) # weakly down-sampled side\n",
    "\n",
    "  first_half_pts = np.asarray(first_half.points) \n",
    "  secn_half_pts = np.asarray(secn_half.points)\n",
    "  full_pcd_pts = np.vstack((first_half_pts, secn_half_pts))\n",
    "  full_pcd_pts = pts_to_o3d_pcd(full_pcd_pts)\n",
    "  return full_pcd_pts\n",
    "\n",
    "def preprocess_point_cloud(source, target, \n",
    "                           voxel_size, max_nn_normal=max_preproc_nn_normal, \n",
    "                           max_nn_fpfh=max_preproc_nn_fpfh, tgSrcFactor=tgSrcFactor, fps_dnsamp_factor=fps_dnsamp_factor):\n",
    "    print(\":: Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    # pts = pcd.points\n",
    "    # size = len(source.points)\n",
    "    # if (len(target.points) > 1000):\n",
    "    #   target = target.farthest_point_down_sample(len(target.points))\n",
    "    size_factor = len(source.points) / len(target.points)\n",
    "    if (size_factor >= 1):\n",
    "      # print(len(target.points), fps_dnsamp_factor, len(target.points)//fps_dnsamp_factor)\n",
    "      # src_pcd_down = source.farthest_point_down_sample(len(source.points)//fps_dnsamp_factor)\n",
    "      # src_pcd_down = source.voxel_down_sample(voxel_size=0.019)\n",
    "      # src_pcd_down = source.voxel_down_sample(voxel_size=voxel_size)\n",
    "      src_pcd_down = half_voxel_dnsample(source, voxel_size=voxel_size)\n",
    "    else: \n",
    "      src_pcd_down = source\n",
    "    # src_pcd_down = source\n",
    "    # tg_pcd_down = target\n",
    "    tg_pcd_down = target.farthest_point_down_sample(int(tgSrcFactor*len(src_pcd_down.points)))\n",
    "    # src_pcd_down = source.farthest_point_down_sample(int(size/5))\n",
    "    # src_pcd_down = source\n",
    "\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    src_pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=max_nn_normal))\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    src_pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        src_pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=max_nn_fpfh))\n",
    "\n",
    "\n",
    "    print(\":: Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    tg_pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=max_nn_normal))\n",
    "    print(\":: Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    tg_pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        tg_pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=max_nn_fpfh))\n",
    "\n",
    "    return src_pcd_down, src_pcd_fpfh, tg_pcd_down, tg_pcd_fpfh\n",
    "\n",
    "def prepare_dataset(voxel_size, source, target):\n",
    "    print(\":: Load two point clouds and disturb initial pose.\")\n",
    "\n",
    "    # trans_init = np.asarray([[0.0, 0.0, 1.0, 0.0], [1.0, 0.0, 0.0, 0.0],\n",
    "    #                          [0.0, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0]])\n",
    "    # source.transform(trans_init)\n",
    "\n",
    "    # source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    # target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    source_down, source_fpfh, target_down, target_fpfh = preprocess_point_cloud(source, target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh\n",
    "\n",
    "def execute_global_registration(source_down, target_down, source_fpfh,\n",
    "                                target_fpfh, voxel_size, dist_voxel_factor=dist_voxel_factor):\n",
    "  distance_threshold = voxel_size * dist_voxel_factor\n",
    "  # print(\":: RANSAC registration on downsampled point clouds.\")\n",
    "  # print(\"   Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "  # print(\"   we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "  result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "      source_down, target_down, source_fpfh, target_fpfh, True,\n",
    "      distance_threshold,\n",
    "      o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "      3, [\n",
    "          o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "              0.9),\n",
    "          o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "              distance_threshold)\n",
    "      ], o3d.pipelines.registration.RANSACConvergenceCriteria(10000000, 0.99999))\n",
    "  return result\n",
    "\n",
    "\n",
    "def normalization(data):\n",
    "    _range = np.max(data) - np.min(data)\n",
    "    return (data - np.min(data)) / _range\n",
    "\n",
    "def standardization(data):\n",
    "    mu = np.mean(data, axis=0)\n",
    "    sigma = np.std(data, axis=0)\n",
    "    return (data - mu) / sigma\n",
    "\n",
    "def visualize_rre(Trans, rmse, cdists, optim_index):\n",
    "  rmseList = np.array(rmse)\n",
    "  cdistsList = np.array(cdists)\n",
    "  rreList = [np.rad2deg(compute_rre((inv_extrinsic @ t)[:3,:3], gt_T_world[:3,:3])) for t in Trans]\n",
    "  rteList = [compute_rte((inv_extrinsic @ t)[:3,3], gt_T_world[:3,3]) for t in Trans]\n",
    "  print(\"The following gives rre and rte max indices and values:\")\n",
    "  print(np.max(rreList), np.argmax(rreList))\n",
    "  print(np.min(rteList), np.argmin(rteList))\n",
    "  # print(rteList[np.argmax(rreList)], np.argmax(rreList))\n",
    "  rreList, rteList = np.array(rreList), np.array(rteList) \n",
    "  # print((rreList>=175))\n",
    "  # print((rteList<=0.01))\n",
    "  # np.intersect1d(np.where(rreList>=175), np.where(rteList<=0.01)) \n",
    "  goodList = rreList[np.intersect1d(np.where(rreList>=175), np.where(rteList<=0.01))]\n",
    "  print(\"Good list under current parameter sets:\")\n",
    "  print(goodList, len(goodList))\n",
    "  print(\"Good list rmse and cdist:\")\n",
    "  print(rmseList[np.intersect1d(np.where(rreList>=175), np.where(rteList<=0.01))])\n",
    "  print(cdistsList[np.intersect1d(np.where(rreList>=175), np.where(rteList<=0.01))])\n",
    "  print(\"Fractioned optimal rmse and cdist:\")\n",
    "  print(rmseList[optim_index])\n",
    "  print(cdistsList[optim_index])\n",
    "  print(\"Global optimal rmse and cdist, with indices:\")\n",
    "  print(np.min(rmseList), np.argmin(rmseList))\n",
    "  print(np.min(cdistsList), np.argmin(cdistsList))\n",
    "  return 0\n",
    "\n",
    "def get_o3d_icp_with_global_registration(source_pcd, target_pcd, \n",
    "                                         voxel_size=icp_global_voxel_size, \n",
    "                                         init_random_time=init_random_time, \n",
    "                                         cdistFrac = cdistFrac):\n",
    "  source_pcd_o3d, target_pcd_o3d = o3d.geometry.PointCloud(), o3d.geometry.PointCloud()\n",
    "  source_pcd_o3d.points = o3d.utility.Vector3dVector(source_pcd)\n",
    "  target_pcd_o3d.points = o3d.utility.Vector3dVector(target_pcd)\n",
    "  source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(voxel_size, source_pcd_o3d, target_pcd_o3d)\n",
    "  print(source, target)\n",
    "  print(source_down, target_down)\n",
    "\n",
    "  # perform multiple RANSAC inits, and choose the best amongest them\n",
    "  Trans, rmse, cdists = [], [], []\n",
    "  for i in tqdm(range(init_random_time)):\n",
    "    result_ransac = execute_global_registration(source_down, target_down, \\\n",
    "                      source_fpfh, target_fpfh, \\\n",
    "                      voxel_size)\n",
    "    # result_ransac = execute_fast_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size)\n",
    "    # print(\"result_ransac: \")\n",
    "    # print(result_ransac)\n",
    "    # print(result_ransac.transformation.shape)\n",
    "    # o3dvis([getTransPcd(source_down.points, result_ransac.transformation), target_down.points])\n",
    "    # result_icp = refine_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size, result_ransac.transformation)\n",
    "    # TODO: Fetch the best initialization as the result\n",
    "    result_icp = get_o3d_icp(source_down.points, target_down.points, init=result_ransac.transformation)\n",
    "    # print(\"result_icp:\")\n",
    "    # print(result_icp)\n",
    "    tr = result_icp.transformation\n",
    "    trans_source_down = copy.deepcopy(source_down)\n",
    "    trans_source_down = trans_source_down.transform(tr)\n",
    "    dists = target_down.compute_point_cloud_distance(trans_source_down)\n",
    "    dists = np.asarray(dists)\n",
    "    # print(\"chamfer dist:\")\n",
    "    # print(dists)\n",
    "    # print(dists)\n",
    "    Trans.append(tr)\n",
    "    rmse.append(result_icp.inlier_rmse)\n",
    "    cdists.append(np.sum(dists))\n",
    "    # draw_registration_result(source_down, target_down, result_icp.transformation)\n",
    "  print(\"cdist list:\")\n",
    "  print(cdists)\n",
    "  print(np.min(cdists))\n",
    "  print(np.argmin(cdists))\n",
    "  o3dvis([getTransPcd(source_down.points, Trans[np.argmin(np.array(cdists)+np.array(rmse))]), target_down.points])\n",
    "  # return Trans[np.argmin(rmse)]\n",
    "  cdistsNorm = standardization(np.array(cdists))\n",
    "  rmseNorm = standardization(np.array(rmse))\n",
    "  optim_index = np.argmin((1-cdistFrac)*rmseNorm+cdistFrac*cdistsNorm)\n",
    "  # visualize_rre(Trans, rmse, cdists, optim_index)\n",
    "  visualize_rre(Trans, rmseNorm, cdistsNorm, optim_index)\n",
    "  return Trans[np.argmin((1-cdistFrac)*rmseNorm+cdistFrac*cdistsNorm)]\n",
    "\n",
    "def pts_to_o3d_pcd(pts):\n",
    "  \"\"\"Transform to o3d pcd\"\"\"\n",
    "  pcd = o3d.geometry.PointCloud()\n",
    "  pcd.points = o3d.utility.Vector3dVector(pts)\n",
    "  return pcd\n",
    "\n",
    "def o3d_Vec_to_o3d_pcd(pts):\n",
    "  \"\"\"Transform to o3d pcd\"\"\"\n",
    "  pcd = o3d.geometry.PointCloud()\n",
    "  pcd.points = pts\n",
    "  return pcd\n",
    "\n",
    "def o3dvis(pts):\n",
    "  o3d.visualization.draw_geometries([pts_to_o3d_pcd(pt) for pt in pts])\n",
    "  return 0\n",
    "\n",
    "def getTransPcd(source_pcd, T):\n",
    "  return source_pcd @ T[:3, :3].T + T[:3, 3]\n",
    "\n",
    "\n",
    "# Define the data point to visualize\n",
    "train_vis_varianct, train_vis_index, object_ids, vis_id = \"1-1-4\", 0, [35, 39, 48, 51, 58], 35\n",
    "rgb_file = \"datas/1-1-4_color_kinect.png\"\n",
    "depth_file = \"datas/1-1-4_depth_kinect.png\"\n",
    "label_file = \"datas/1-1-4_label_kinect.png\"\n",
    "meta_file = \"datas/1-1-4_meta.pkl\"\n",
    "\n",
    "\n",
    "# Load scene meta info\n",
    "meta_vis = get_meta(meta_file)\n",
    "scales = meta_vis[\"scales\"]\n",
    "print(meta_vis.keys())\n",
    "intrinsic = meta_vis[\"intrinsic\"]\n",
    "extrinsic = meta_vis[\"extrinsic\"]\n",
    "inv_extrinsic = np.linalg.inv(extrinsic)\n",
    "gt_T_world = meta_vis[\"poses_world\"][vis_id]\n",
    "gt_T = extrinsic @ gt_T_world\n",
    "# print(gt_T.shape)\n",
    "gt_T = meta_vis[\"poses_world\"][vis_id]\n",
    "# Fetch source point cloud from model dictionary\n",
    "# print(object_models)\n",
    "\n",
    "\n",
    "# Reconstruct source and target point clouds (in camera frame)\n",
    "print(object_name)\n",
    "object_name = object_models_name[vis_id]\n",
    "vis_pcd_source = object_models[object_name]\n",
    "vis_pcd_source = vis_pcd_source * scales[vis_id]\n",
    "vis_pcd_target = get_object_point_cloud(get_label(label_file), \\\n",
    "                    vis_id, \\\n",
    "                    get_depth(depth_file), \\\n",
    "                    intrinsic)\n",
    "\n",
    "# o3dvis([vis_pcd_source])\n",
    "\n",
    "print(\"src and tg len:\")\n",
    "print(len(vis_pcd_target), len(vis_pcd_source))\n",
    "\n",
    "\n",
    "# Perform ICP\n",
    "# source_pcd, target_pcd = vis_pcd_target, vis_pcd_source\n",
    "source_pcd, target_pcd = vis_pcd_source, vis_pcd_target\n",
    "# source_pcd = np.hstack((source_pcd, np.ones((len(source_pcd), 1))))\n",
    "# target_pcd = np.hstack((target_pcd, np.ones((len(target_pcd), 1))))\n",
    "# source_pcd, target_pcd = (source_pcd @ np.linalg.inv(extrinsic).T), (target_pcd @ np.linalg.inv(extrinsic).T)\n",
    "# source_pcd = np.array([x[:-1]/x[-1] for x in source_pcd])\n",
    "# target_pcd = np.array([x[:-1]/x[-1] for x in target_pcd])\n",
    "# print(source_pcd.shape, target_pcd.shape)\n",
    "# o3dvis([source_pcd, target_pcd])\n",
    "T = get_o3d_icp_with_global_registration(source_pcd, target_pcd)\n",
    "# T = get_o3d_icp_tensor(source_pcd, target_pcd)\n",
    "# T = get_o3d_icp(source_pcd, target_pcd) # should use T.transformation to get transformation matrix!\n",
    "# T = icp(source_pcd, target_pcd, 100)\n",
    "T_world = inv_extrinsic @ T\n",
    "TrEstiPcd = source_pcd @ T[:3, :3].T + T[:3, 3]\n",
    "TrGtPcd = source_pcd @ gt_T[:3, :3].T + gt_T[:3, 3]\n",
    "\n",
    "o3dvis([TrEstiPcd, target_pcd])\n",
    "\n",
    "\n",
    "print(len(TrEstiPcd), len(TrGtPcd))\n",
    "# print(TrEstiPcd)\n",
    "# print(TrGtPcd)\n",
    "# o3d.visualization.draw_geometries([pts_to_o3d_pcd(TrEstiPcd), pts_to_o3d_pcd(TrGtPcd)])\n",
    "\n",
    "# T = np.eye(4)\n",
    "print(source_pcd.shape)\n",
    "print(target_pcd.shape)\n",
    "print(\"GT T:\")\n",
    "print(gt_T)\n",
    "print(\"GT T world:\")\n",
    "print(gt_T_world)\n",
    "print(\"pred T:\")\n",
    "print(T)\n",
    "print(\"pred T world:\")\n",
    "print(T_world)\n",
    "# rre = np.rad2deg(compute_rre(T[:3, :3], gt_T[:3, :3]))\n",
    "# rte = compute_rte(T[:3, 3], gt_T[:3, 3])\n",
    "rre = np.rad2deg(compute_rre(T_world[:3, :3], gt_T_world[:3, :3]))\n",
    "rte = compute_rte(T_world[:3, 3], gt_T_world[:3, 3])\n",
    "print(f\"rre={rre}, rte={rte}\")\n",
    "# show_points(target_pcd, \"Target pcd\")\n",
    "# show_points(source_pcd, \"Source pcd\")\n",
    "# show_points(TrEstiPcd, \"Transformed source pcd\")\n",
    "# show_points(TrGtPcd, \"GT Transformed source pcd\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualize given pcd\"\"\"\n",
    "train_vis_varianct, train_vis_index, object_ids, vis_id = \"1-1-1\", 0, [35, 39, 48, 51, 58], 58\n",
    "object_name = object_models_name[vis_id]\n",
    "meta_vis = get_meta(meta_file)\n",
    "scales = meta_vis[\"scales\"]\n",
    "vis_pcd_source = object_models[object_name]\n",
    "vis_pcd_source = vis_pcd_source * scales[vis_id]\n",
    "o3d.visualization.draw_geometries([pts_to_o3d_pcd(vis_pcd_source)])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
